Using:
    pip3
    Python3.9.6
    venv

venv instruction:
    install venv:
        pip3 install virtualenv
    create venv folder:
        virtualenv <name>
    activate venv:
        source <name>/bin/activate 
        pip3 install -r requirements.txt
    exit venv:
        deactivate



I ran 
    pip3 install llama-cpp-python==0.1.78 
to install verion 0.1.78. If your model is .ggml
then use a version less than 0.1.79. If your model is .gguf
then use a version greater than 0.1.79.

Orca-3b setup:
    go to 
        https://huggingface.co/TheBloke/orca_mini_3B-GGML/tree/main
    click files and versions and download 
        orca-mini-3b.ggmlv3.q4_1.bin
    move download to the models folder

LLama2-7b setup:
    go to 
        https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main
    click files and versions and download
         llama-2-7b-chat.ggmlv3.q4_1.bin
    move download to the models folder

Setup:
    In LLM-Server folder create .env file: Example below
        HOST= "127.0.0.1"
        PORT= "8000"
        LLM_TAG= "llm-server"
        LLM_PREFIX="/llm-server"
        MODEL_PATH ="/llm-models/llama-2-7b-chat.ggmlv3.q4_1.bin"
        LLAMA_N_CTX="512"
        LLAMA_N_BATCH="32"
        LLAMA_N_VERBOSE="False"
    To start run:
        main.py
    To see api documentation go to:
        http://<host>:<port>/docs#/
